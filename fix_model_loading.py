import os
import subprocess
import shutil
import sys

def run_pip_command(command):
    print(f"\n>>> Running: {command}")
    subprocess.check_call([sys.executable, "-m", "pip"] + command.split())

def uninstall_conflicting_packages():
    print("ğŸ”§ Uninstalling incompatible packages...")
    packages = ["torch", "torchvision", "torchaudio", "sentence-transformers", "transformers"]
    for package in packages:
        try:
            run_pip_command(f"uninstall -y {package}")
        except Exception as e:
            print(f"âš ï¸ Could not uninstall {package}: {e}")

def install_compatible_packages():
    print("ğŸ“¦ Installing compatible versions...")
    run_pip_command("install torch==2.0.1 torchvision==0.15.2 torchaudio==2.0.2")
    run_pip_command("install sentence-transformers --upgrade")
    run_pip_command("install transformers --upgrade")

def delete_model_cache():
    print("ğŸ§¹ Clearing model cache...")
    home = os.path.expanduser("~")
    cache_path = os.path.join(home, ".cache", "huggingface", "hub", "models--sentence-transformers--all-MiniLM-L6-v2")
    
    if os.path.exists(cache_path):
        try:
            shutil.rmtree(cache_path)
            print("âœ… Deleted model cache successfully.")
        except Exception as e:
            print(f"âŒ Failed to delete model cache: {e}")
    else:
        print("â„¹ï¸ Model cache folder not found â€” skipping.")

def main():
    print("=== ğŸš€ Starting Fix Script for Meta Tensor Error ===")
    uninstall_conflicting_packages()
    install_compatible_packages()
    delete_model_cache()
    print("âœ… All done! You can now rerun your Streamlit app.")
    print("ğŸ‘‰ Run: streamlit run app.py")

if __name__ == "__main__":
    main()
